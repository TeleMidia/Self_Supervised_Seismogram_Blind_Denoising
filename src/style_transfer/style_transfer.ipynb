{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import random\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from style_transfer import run_style_tranfer, gen_mask, save_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(clean_folder, file_list):\n",
    "    IMG_SIZE = 200\n",
    "    dataset_base_name = clean_folder.split(\"/\")[-1]\n",
    "    noisy_dataset1 = dataset_base_name+\"_noisy_A1\"\n",
    "    noisy_dataset2 = dataset_base_name+\"_noisy_A2\"\n",
    "    noisy_dataset3 = dataset_base_name+\"_noisy_B1\"\n",
    "    noisy_dataset4 = dataset_base_name+\"_noisy_C1\"\n",
    "    noisy_dataset5 = dataset_base_name+\"_noisy_C2\"\n",
    "    noisy_dataset6 = dataset_base_name+\"_noisy_D1\"\n",
    "    \n",
    "    dataset_list = []\n",
    "    dataset_name_list = []\n",
    "    \n",
    "    for folder_ in glob.glob(clean_folder + \"/**\"):\n",
    "        folder_ = folder_.replace(\"\\\\\", \"/\")\n",
    "        folder_number = folder_.split(\"/\")[-1]\n",
    "        \n",
    "        if folder_number in file_list:\n",
    "            print(folder_number)\n",
    "            \n",
    "            for piece_ in glob.glob( os.path.join(clean_folder,folder_number)+ \"/*.tiff\"):\n",
    "                piece_ = piece_.replace(\"\\\\\", \"/\")\n",
    "                #print(piece_)\n",
    "                \n",
    "                clean_img = np.array(Image.open(piece_)) \n",
    "                assert clean_img.shape == (IMG_SIZE, IMG_SIZE)\n",
    "                \n",
    "                if np.std(clean_img)> 0.001:\n",
    "                    \n",
    "                    sample_list = []\n",
    "                    sample_list.append(clean_img)\n",
    "                    dataset_name_list.append(piece_)\n",
    "                    \n",
    "                    noisy_img1 = np.array(Image.open(piece_.replace(dataset_base_name, noisy_dataset1)))\n",
    "                    assert clean_img.shape == (IMG_SIZE, IMG_SIZE)\n",
    "                    sample_list.append(noisy_img1)\n",
    "                    \n",
    "                    noisy_img2 = np.array(Image.open(piece_.replace(dataset_base_name, noisy_dataset2)))\n",
    "                    assert clean_img.shape == (IMG_SIZE, IMG_SIZE)\n",
    "                    sample_list.append(noisy_img2)\n",
    "                    \n",
    "                    noisy_img3 = np.array(Image.open(piece_.replace(dataset_base_name, noisy_dataset3)))\n",
    "                    assert clean_img.shape == (IMG_SIZE, IMG_SIZE)\n",
    "                    sample_list.append(noisy_img3)\n",
    "                    \n",
    "                    noisy_img4 = np.array(Image.open(piece_.replace(dataset_base_name, noisy_dataset4)))\n",
    "                    assert clean_img.shape == (IMG_SIZE, IMG_SIZE)\n",
    "                    sample_list.append(noisy_img4)\n",
    "                    \n",
    "                    noisy_img5 = np.array(Image.open(piece_.replace(dataset_base_name, noisy_dataset5)))\n",
    "                    assert clean_img.shape == (IMG_SIZE, IMG_SIZE)\n",
    "                    sample_list.append(noisy_img5)\n",
    "                    \n",
    "                    noisy_img6 = np.array(Image.open(piece_.replace(dataset_base_name, noisy_dataset6)))\n",
    "                    assert clean_img.shape == (IMG_SIZE, IMG_SIZE)\n",
    "                    sample_list.append(noisy_img6)\n",
    "                    \n",
    "                    #plt.imshow( np.hstack((noisy_img1,noisy_img2,noisy_img3,noisy_img4,noisy_img5,noisy_img6)) , cmap=\"bwr\", vmin=0, vmax=1)\n",
    "                    #plt.axis('off')\n",
    "                    #plt.pause(0.1)\n",
    "                    \n",
    "                    dataset_list.append(np.array(sample_list))\n",
    "\n",
    "    return np.array(dataset_list), dataset_name_list\n",
    "    \n",
    "dataset_tensor, file_name_list = load_dataset(\"../../dataset/croped/train/Dataset_Sintetico_02\", [\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\"])\n",
    "\n",
    "print(dataset_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.2),\n",
    "    ('conv2_1', 0.0),\n",
    "    ('conv3_1', 0.0),\n",
    "    ('conv4_1', 0.0),\n",
    "    ('conv5_1', 8.0)]\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "num_saples = dataset_tensor.shape[0]\n",
    "\n",
    "border = np.ones((200,5))\n",
    "\n",
    "print(num_saples)\n",
    "assert len(file_name_list) == num_saples\n",
    "\n",
    "for i in range(0,num_saples):\n",
    "    img_clean = dataset_tensor[i,0,:,:]\n",
    "    list_noisy = []  \n",
    "    list_noisy.append(dataset_tensor[i,1,:,:])\n",
    "    list_noisy.append(dataset_tensor[i,2,:,:])\n",
    "    list_noisy.append(dataset_tensor[i,3,:,:])\n",
    "    list_noisy.append(dataset_tensor[i,4,:,:])\n",
    "    list_noisy.append(dataset_tensor[i,5,:,:])\n",
    "    list_noisy.append(dataset_tensor[i,6,:,:])\n",
    "    \n",
    "    \n",
    "    for j in range(0,6):\n",
    "        img_noisy = list_noisy[j]\n",
    "        \n",
    "        gen_filename = file_name_list[i].replace(\"train\", \"gen\").replace(\".tiff\", \"_\"+str(j)+\".tiff\")\n",
    "        \n",
    "        if os.path.exists(gen_filename):\n",
    "            print(\"pass \", gen_filename)\n",
    "            continue\n",
    "        \n",
    "        gen_image = run_style_tranfer(STYLE_W=STYLE_LAYERS, content_image=img_clean, style_image=img_noisy, num_epochs=epochs, lr=2.0)\n",
    "        \n",
    "        gen_image = Image.fromarray(gen_image) \n",
    "        \n",
    "        head, _ = os.path.split(gen_filename)\n",
    "        if not os.path.exists(head):\n",
    "            os.makedirs(head)\n",
    "        \n",
    "        gen_image.save(gen_filename)\n",
    "    \n",
    "\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
